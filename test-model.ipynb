{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc41424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train:  708405\n",
      "# of test:  708420\n",
      "number of 1s in test:  29444\n",
      "number of 0s in test:  678976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from utils import read_data, iterate_batches, apply_adjustment, sliding_window_anomaly_detection, get_precision_recall_f1\n",
    "\n",
    "window_size = 50  # size of the window\n",
    "dataset_list = [\"MSL\", \"PSM\", \"SMAP\", \"SMD\", \"SWAT\"]\n",
    "dataset = dataset_list[2]\n",
    "\n",
    "flag_train_composite = True\n",
    "flag_AE = True\n",
    "\n",
    "if flag_train_composite:\n",
    "    if flag_AE:\n",
    "        MODEL_PATH = \"models/\" + dataset + \"/\" + dataset + \"-AE-FAR\"\n",
    "    else:\n",
    "        MODEL_PATH = \"models/\" + dataset + \"/\" + dataset + \"-VAE-FAR\"\n",
    "else:\n",
    "    if flag_AE:\n",
    "        MODEL_PATH = \"models/\" + dataset + \"/\" + dataset + \"-AE\"\n",
    "    else:\n",
    "        MODEL_PATH = \"models/\" + dataset + \"/\" + dataset + \"-VAE\"\n",
    "\n",
    "\n",
    "train_data, test_data, val_data, test_labels = read_data(dataset)\n",
    "input_dim = train_data.shape[1]\n",
    "\n",
    "print(\"# of train: \", train_data.shape)\n",
    "print(\"# of test: \", test_data.shape)\n",
    "print(\"# of labels: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17acd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test  708420\n",
      "predictions  708370\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "window_size = 50  # size of the window\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        attention_weights = self.attention(inputs)\n",
    "        weighted_input = inputs * attention_weights\n",
    "        return weighted_input, attention_weights\n",
    "\n",
    "class MSEFeedbackRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(MSEFeedbackRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.unsqueeze(1)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out)  # Apply the fully connected layer to each time step\n",
    "        return out\n",
    "\n",
    "# CompositeModel: AE-FAR or VAE-FAR according to the autoencoder type\n",
    "class CompositeModel(nn.Module):\n",
    "    def __init__(self, autoencoder, rnn, attention_dim=64):\n",
    "        super(CompositeModel, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.rnn = rnn\n",
    "        self.attention = AttentionLayer(input_dim= input_dim+1, hidden_dim=attention_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # reconstructed, mean, log = self.autoencoder(x) # For VAE\n",
    "        reconstructed = self.autoencoder(x) #For AE\n",
    "        mse_error = ((y - reconstructed) ** 2).mean(dim=1, keepdim=True)\n",
    "\n",
    "        combined_input = torch.cat((reconstructed, mse_error), dim=1)\n",
    "        combined_input, attention_weights = self.attention(combined_input)\n",
    "\n",
    "        rnn_output = self.rnn(combined_input)\n",
    "        rnn_output = rnn_output.squeeze(1)\n",
    "        \n",
    "        adjusted_reconstructed = reconstructed + rnn_output\n",
    "        return adjusted_reconstructed, mse_error, rnn_output\n",
    "\n",
    "\n",
    "model = torch.load(MODEL_PATH + \".pt\", map_location=device)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "batch_size = 128  # size of each batch\n",
    "\n",
    "\n",
    "X_test = torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "\n",
    "predictions = None\n",
    "for batch, y_batch in iterate_batches(X_test, window_size, batch_size):\n",
    "    \n",
    "    if flag_train_composite:\n",
    "        y_pred, mse_error, rnn_output = model(batch, y_batch)\n",
    "    elif flag_AE:\n",
    "        y_pred = model(batch)\n",
    "    else:\n",
    "        y_pred, mean, log_var = model(batch)    \n",
    "    \n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    if predictions is None:\n",
    "        predictions = y_pred\n",
    "    else:\n",
    "        predictions = np.concatenate((predictions, y_pred), axis=0)\n",
    "\n",
    "print(\"X_test \", len(X_test))\n",
    "print(\"predictions \", len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9cc64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.12\n",
      "adjusted:  (0.6272, 0.5201, 0.5686)\n",
      "adjusted with sliding:  (0.9201, 0.882, 0.9006)\n"
     ]
    }
   ],
   "source": [
    "if \"SWAT\" in MODEL_PATH:\n",
    "    th_factor = 5.0\n",
    "elif \"SMD\" in MODEL_PATH:\n",
    "    th_factor = 5.0\n",
    "elif \"MSL\" in MODEL_PATH:\n",
    "    th_factor = 6.5\n",
    "elif \"PSM\" in MODEL_PATH:\n",
    "    th_factor = 4.0\n",
    "elif \"SMAP\" in MODEL_PATH:\n",
    "    th_factor = 6.5\n",
    "\n",
    "\n",
    "test_data_tmp = test_data[window_size:]\n",
    "true_labels = test_labels[window_size:]\n",
    "\n",
    "mse = np.mean(np.power(test_data_tmp - predictions, 2), axis=1)\n",
    "\n",
    "print(\"dataset: \", dataset)\n",
    "print(\"model: \", MODEL_PATH)\n",
    "print(\"threshold: \", th_factor)\n",
    "\n",
    "\n",
    "pred_y, dynamic_threshold = sliding_window_anomaly_detection(mse, window_size, threshold_factor=th_factor)\n",
    "gt, pred_adjusted = apply_adjustment(true_labels, pred_y)\n",
    "print(\"adjusted with sliding: \", get_precision_recall_f1(gt, pred_adjusted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
